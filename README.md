<h3 align="center"><img src="https://raw.githubusercontent.com/feiskyer/chatgpt-copilot/main/images/ai-logo.png" height="64"><br>An VS Code ChatGPT Copilot Extension</h3>

<p align="center">
    <a href="https://marketplace.visualstudio.com/items?itemName=feiskyer.chatgpt-copilot" alt="Marketplace version">
        <img src="https://img.shields.io/visual-studio-marketplace/v/feiskyer.chatgpt-copilot?color=orange&label=VS%20Code" />
    </a>
    <a href="https://marketplace.visualstudio.com/items?itemName=feiskyer.chatgpt-copilot" alt="Marketplace download count">
        <img src="https://img.shields.io/visual-studio-marketplace/d/feiskyer.chatgpt-copilot?color=blueviolet&label=Downloads" />
    </a>
    <a href="https://github.com/feiskyer/chatgpt-copilot" alt="Github star count">
        <img src="https://img.shields.io/github/stars/feiskyer/chatgpt-copilot?color=blue&label=Github%20Stars" />
    </a>
</p>

## The Most Loved Open-Source ChatGPT Extension for VS Code

ChatGPT Copilot is a powerful and telemetry-free extension for Visual Studio Code, bringing the capabilities of ChatGPT directly into your coding environment.

## Features

- ü§ñ Supports GPT-5, o1/o3, Claude, Gemini, Ollama, Claude Code, Github Copilot and other OpenAI-compatible local models with your API key from OpenAI, Azure OpenAI Service, Google, Anthropic or other providers.
- üí• Model Context Protocol (MCP) to bring your own tools and DeepClaude (DeepSeek R1 + Claude) mode for best AI responses.
- üìÇ Chat with your Files: Add multiple files and images to your chat using `@` for seamless collaboration.
- üìÉ Streaming Answers: Receive real-time responses to your prompts in the sidebar conversation window.
- ‚ú® Inline Completions: See real-time code suggestions in the editor that you can accept with Tab or Enter.
- üìñ Prompt Manager: Chat with your own prompts (use # to search).
- üî• Tool calls via prompt parsing for models that don't support native tool calling.
- üìù Code Assistance: Create files or fix your code with one click or keyboard shortcuts.
- ‚û°Ô∏è Export Conversations: Export all your conversation history at once in Markdown format.
- üì∞ Custom Prompt Prefixes: Customize what you are asking ChatGPT with ad-hoc prompt prefixes.
- üíª Seamless Code Integration: Copy, insert, or create new files directly from ChatGPT's code suggestions.
- ‚ûï Editable Prompts: Edit and resend previous prompts.
- üõ°Ô∏è Telemetry Free: No usage data is collected.

## Chat Modes

Chat offers specialized modes so you can choose the right workflow for every task. Pick a mode from the dropdown at the top of the chat panel, press <kbd>Ctrl</kbd>+<kbd>.</kbd> to cycle quickly, or customize shortcuts from the extension settings.

| Mode  | Best for                            | Architecture & Capabilities                                                                                 | Tool Access                |
| ----- | ----------------------------------- | ------------------------------------------------------------------------------------------------------------ | ------------------------- |
| Agent | Complex changes and refactoring     | Iterative plan-act-observe loop (ReAct-style) that searches the repo, proposes diffs, and runs commands/tests | All tools enabled          |
| Ask   | Learning and investigation          | Read-only exploration of the workspace without modifying files                                              | Search and read-only tools |
| Plan  | Large or multi-step implementations | ReWOO-style planning that researches context, asks clarifiers, and drafts a multi-step plan for later execution | All tools enabled          |

### How each mode works

- **Agent Mode** ‚Äì The autonomous controller continuously decides which tool to call next (search, edit, or run). It surfaces proposed diffs for approval and can execute shell commands or tests, making it ideal for end-to-end feature work.
- **Ask Mode** ‚Äì Keeps the workspace unchanged while the assistant answers questions. Use it to understand code, explore APIs, or gather references safely.
- **Plan Mode** ‚Äì Activates a dedicated planner that gathers context, asks follow-up questions, and produces an editable plan before any edits occur. Once approved, the plan can be executed by Agent Mode or adapted manually.

> üí° **Tip:** Understanding how each mode reasons‚Äîand when it will edit files versus only observing‚Äîhelps you pick the most effective workflow before you start a session.

## Recent Release Highlights

- **v4.10**: Add Claude Code provider.
- **v4.9**: Add prompt based tool calls for models that don't support native tool calling.
- **v4.8**: New LOGO and new models.
- **v4.7**: Added Model Context Protocol (MCP) integration.
- **v4.6**: Added prompt manager, DeepClaude mode (DeepSeek + Claude) mode, Github Copilot provider and chat with files.

## Installation

- Install the extension from the [Visual Studio Marketplace](https://marketplace.visualstudio.com/items?itemName=feiskyer.chatgpt-copilot) or search `ChatGPT Copilot` in VScode Extensions and click install.
- Reload Visual Studio Code after installation.

## Supported Models & Providers

### **AI Providers**

The extension supports major AI providers with hundreds of models:

| Provider           | Models                                            | Special Features                   |
| ------------------ | ------------------------------------------------- | ---------------------------------- |
| **OpenAI**         | GPT-5, GPT-4o, GPT-4, o1, o3, o4-mini             | Reasoning models, function calling |
| **Anthropic**      | Claude Sonnet 4, Claude 3.5 Sonnet, Claude Opus 4 | Advanced reasoning, large context  |
| **Google**         | Gemini 2.5 Pro, Gemini 2.0 Flash, Gemini Pro      | Search grounding, multimodal       |
| **GitHub Copilot** | GPT-4o, Claude Sonnet 4, o3-mini, Gemini 2.5 Pro  | Built-in VS Code authentication    |
| **Claude Code**    | CLaude Sonnet/Opus 4                              | Vibe coding in SOLO mode           |
| **DeepSeek**       | DeepSeek R1, DeepSeek Reasoner                    | Advanced reasoning capabilities    |
| **Azure OpenAI**   | GPT-4o, GPT-4, o1                                 | Enterprise-grade security          |
| **Azure AI**       | Various non-OpenAI models                         | Microsoft's AI model hub           |
| **Ollama**         | Llama, Qwen, CodeLlama, Mistral                   | Local model execution              |
| **Groq**           | Llama, Mixtral, Gemma                             | Ultra-fast inference               |
| **Perplexity**     | Llama, Mistral models                             | Web-enhanced responses             |
| **xAI**            | Grok models                                       | Real-time information              |
| **Mistral**        | Mistral Large, Codestral                          | Code-specialized models            |
| **Together**       | Various open-source models                        | Community models                   |
| **OpenRouter**     | 200+ models                                       | Access to multiple providers       |

## AI Services

Configure the extension by setting your API keys and preferences in the settings.

| Configuration | Description                                                                                                                                                                                                                                     |
| ------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| API Key       | Required, get from [OpenAI](https://platform.openai.com/account/api-keys), [Azure OpenAI](https://azure.microsoft.com/en-us/products/ai-services/openai-service), [Anthropic](https://console.anthropic.com/settings/keys) or other AI services |
| API Base URL  | Optional, default to "<https://api.openai.com/v1>"                                                                                                                                                                                              |
| Model         | Optional, default to "gpt-4o"                                                                                                                                                                                                                   |

Refer to the following sections for more details on configuring various AI services.

<details>

<summary> OpenAI </summary>

> **Special notes for ChatGPT users**:
> OpenAI API is billed separately from ChatGPT App. You need to add credits to your OpenAI for API usage [here](https://platform.openai.com/settings/organization/billing/overview). Once you add credits to your API, create a new api key and it should work.

| Configuration | Example                                |
| ------------- | -------------------------------------- |
| API Key       | your-api-key                           |
| Model         | gpt-4o                                 |
| API Base URL  | <https://api.openai.com/v1> (Optional) |

</details>

<details>
<summary> Ollama </summary>

Pull your image first from Ollama [library](https://ollama.com/library) and then setup the base URL and custom model.

| Configuration | Example                      |
| ------------- | ---------------------------- |
| API Key       | ollama (Optional)            |
| Model         | custom                       |
| Custom Model  | qwen2.5                      |
| API Base URL  | <http://localhost:11434/v1/> |

</details>

<details>
<summary> DeepSeek </summary>

Ollama provider:

| Configuration | Example                      |
| ------------- | ---------------------------- |
| API Key       | ollama (Optional)            |
| Model         | custom                       |
| Custom Model  | deepseek-r1                  |
| API Base URL  | <http://localhost:11434/v1/> |

DeepSeek provider:

| Configuration | Example                    |
| ------------- | -------------------------- |
| API Key       | your-deepseek-key          |
| Model         | deepseek-reasoner          |
| API Base URL  | <https://api.deepseek.com> |

SiliconFlow (SiliconCloud) provider:

| Configuration | Example                         |
| ------------- | ------------------------------- |
| API Key       | your-siliconflow-key            |
| Model         | custom                          |
| Custom Model  | deepseek-ai/DeepSeek-R1         |
| API Base URL  | <https://api.siliconflow.cn/v1> |

Azure AI Foundry provider:

| Configuration | Example                                              |
| ------------- | ---------------------------------------------------- |
| API Key       | your-azure-ai-key                                    |
| Model         | DeepSeek-R1                                          |
| API Base URL  | https://[endpoint-name].[region].models.ai.azure.com |

</details>

<details>

<summary> Claude Code </summary>

| Configuration    | Example                  |
| ---------------- | ------------------------ |
| Provider         | ClaudeCode.              |
| Claude Code Path | /opt/homebrew/bin/claude |
| Model            | claude-sonnet-4-20250514 |

</details>

<details>
<summary> Anthropic Claude </summary>

| Configuration | Example                                   |
| ------------- | ----------------------------------------- |
| API Key       | your-api-key                              |
| Model         | claude-3-sonnet-20240229                  |
| API Base URL  | <https://api.anthropic.com/v1> (Optional) |

</details>

<details>
<summary> Google Gemini </summary>

| Configuration | Example                                                       |
| ------------- | ------------------------------------------------------------- |
| API Key       | your-api-key                                                  |
| Model         | gemini-2.0-flash-thinking-exp-1219                            |
| API Base URL  | <https://generativelanguage.googleapis.com/v1beta> (Optional) |

</details>

<details>
<summary> Azure OpenAI </summary>

For Azure OpenAI Service, apiBaseUrl should be set to format `https://[YOUR-ENDPOINT-NAME].openai.azure.com/openai/deployments/[YOUR-DEPLOYMENT-NAME]`.

| Configuration | Example                                                                     |
| ------------- | --------------------------------------------------------------------------- |
| API Key       | your-api-key                                                                |
| Model         | gpt-4o                                                                      |
| API Base URL  | <https://endpoint-name.openai.azure.com/openai/deployments/deployment-name> |

</details>

<details>
<summary> Github Copilot </summary>

[Github Copilot](https://github.com/features/copilot) is supported with built-in authentication (a popup will ask your permission when using Github Copilot models).

**Supported Models:**

- **OpenAI Models**: `gpt-3.5-turbo`, `gpt-4`, `gpt-4-turbo`, `gpt-4o`, `gpt-4o-mini`, `gpt-4.1`, `gpt-4.5`
- **Reasoning Models**: `o1-ga`, `o3-mini`, `o3`, `o4-mini`
- **Claude Models**: `claude-3.5-sonnet`, `claude-3.7-sonnet`, `claude-3.7-sonnet-thought`, `claude-sonnet-4`, `claude-opus-4`
- **Gemini Models**: `gemini-2.0-flash`, `gemini-2.5-pro`

| Configuration | Example         |
| ------------- | --------------- |
| Provider      | GitHubCopilot   |
| API Key       | github          |
| Model         | custom          |
| Custom Model  | claude-sonnet-4 |

</details>

<details>
<summary> Github Models </summary>

For [Github Models](https://github.com/marketplace/models), get your Github token from [here](https://github.com/settings/tokens).

| Configuration | Example                                 |
| ------------- | --------------------------------------- |
| API Key       | your-github-token                       |
| Model         | o1                                      |
| API Base URL  | <https://models.inference.ai.azure.com> |

</details>

<details>
<summary> OpenAI compatible Models </summary>

To use OpenAI compatible APIs, you need to set a custom model name: set model to `"custom"` and then specify your custom model name.

Example for [groq](https://console.groq.com/):

| Configuration | Example                          |
| ------------- | -------------------------------- |
| API Key       | your-groq-key                    |
| Model         | custom                           |
| Custom Model  | mixtral-8x7b-32768               |
| API Base URL  | <https://api.groq.com/openai/v1> |

</details>

<details>
<summary> DeepClaude (DeepSeek + Claude) </summary>

| Configuration          | Example                                                       |
| ---------------------- | ------------------------------------------------------------- |
| API Key                | your-api-key                                                  |
| Model                  | claude-3-sonnet-20240229                                      |
| API Base URL           | <https://api.anthropic.com/v1> (Optional)                     |
| Reasoning API Key      | your-deepseek-api-key                                         |
| Reasoning Model        | deepseek-reasoner (or deepseek-r1 regarding to your provider) |
| Reasoning API Base URL | <https://api.deepseek.com> (or your own base URL)             |

</details>

## Commands & Keyboard Shortcuts

The extension provides various commands accessible through the Command Palette (`Ctrl+Shift+P` / `Cmd+Shift+P`) and keyboard shortcuts.

<details>

<summary> Context Menu Commands </summary>

### **Context Menu Commands** (Right-click on selected code)

| Command             | Keyboard Shortcut                           | Description                                     |
| ------------------- | ------------------------------------------- | ----------------------------------------------- |
| **Generate Code**   | `Ctrl+Shift+A` / `Cmd+Shift+A`              | Generate code based on comments or requirements |
| **Add Tests**       | `Ctrl+K Ctrl+Shift+1` / `Cmd+K Cmd+Shift+1` | Generate unit tests for selected code           |
| **Find Problems**   | `Ctrl+K Ctrl+Shift+2` / `Cmd+K Cmd+Shift+2` | Analyze code for bugs and issues                |
| **Optimize**        | `Ctrl+K Ctrl+Shift+3` / `Cmd+K Cmd+Shift+3` | Optimize and improve selected code              |
| **Explain**         | `Ctrl+K Ctrl+Shift+4` / `Cmd+K Cmd+Shift+4` | Explain how the selected code works             |
| **Add Comments**    | `Ctrl+K Ctrl+Shift+5` / `Cmd+K Cmd+Shift+5` | Add documentation comments to code              |
| **Complete Code**   | `Ctrl+K Ctrl+Shift+6` / `Cmd+K Cmd+Shift+6` | Complete partial or incomplete code             |
| **Ad-hoc Prompt**   | `Ctrl+K Ctrl+Shift+7` / `Cmd+K Cmd+Shift+7` | Use custom prompt with selected code            |
| **Custom Prompt 1** | `Ctrl+K Ctrl+Shift+8` / `Cmd+K Cmd+Shift+8` | Apply your first custom prompt                  |
| **Custom Prompt 2** | `Ctrl+K Ctrl+Shift+9` / `Cmd+K Cmd+Shift+9` | Apply your second custom prompt                 |

</details>

<details>
<summary> General Commands </summary>

### **General Commands**

| Command                            | Description                                 |
| ---------------------------------- | ------------------------------------------- |
| `ChatGPT: Ask anything`            | Open input box to ask any question          |
| `ChatGPT: Reset session`           | Clear current conversation and start fresh  |
| `ChatGPT: Clear conversation`      | Clear the conversation history              |
| `ChatGPT: Export conversation`     | Export chat history to Markdown file        |
| `ChatGPT: Manage Prompts`          | Open prompt management interface            |
| `ChatGPT: Toggle Prompt Manager`   | Show/hide the prompt manager panel          |
| `Add Current File to Chat Context` | Add the currently open file to chat context |
| `ChatGPT: Open MCP Servers`        | Manage Model Context Protocol servers       |

</details>

<details>

<summary> Prompt Management </summary>

### **Prompt Management**

- Use `#` followed by prompt name to search and apply saved prompts
- Use `@` to add files to your conversation context
- Access the Prompt Manager through the sidebar for full prompt management

</details>

## Model Context Protocol (MCP)

The extension supports the **Model Context Protocol (MCP)**, allowing you to extend AI capabilities with custom tools and integrations.

<details>

<summary> What is MCP? </summary>

### **What is MCP?**

MCP enables AI models to securely connect to external data sources and tools, providing:

- **Custom Tools**: Integrate your own tools and APIs
- **Data Sources**: Connect to databases, file systems, APIs, and more
- **Secure Execution**: Sandboxed tool execution environment
- **Multi-Step Workflows**: Agent-like behavior with tool chaining

### **MCP Server Types**

The extension supports three types of MCP servers:

| Type                | Description                         | Use Case                             |
| ------------------- | ----------------------------------- | ------------------------------------ |
| **stdio**           | Standard input/output communication | Local command-line tools and scripts |
| **sse**             | Server-Sent Events over HTTP        | Web-based tools and APIs             |
| **streamable-http** | HTTP streaming communication        | Real-time data sources               |

</details>

<details>

<summary> How to configure MCP? </summary>

### **MCP Configuration**

1. **Access MCP Manager**: Use `ChatGPT: Open MCP Servers` command or click the MCP icon in the sidebar
2. **Add MCP Server**: Configure your MCP servers with:
   - **Name**: Unique identifier for the server
   - **Type**: Choose from stdio, sse, or streamable-http
   - **Command/URL**: Executable path or HTTP endpoint
   - **Arguments**: Command-line arguments (for stdio)
   - **Environment Variables**: Custom environment settings
   - **Headers**: HTTP headers (for sse/streamable-http)

### **Example MCP Configurations**

**File System Access (stdio):**

```json
{
  "name": "filesystem",
  "type": "stdio",
  "command": "npx",
  "args": [
    "-y",
    "@modelcontextprotocol/server-filesystem",
    "/path/to/directory"
  ],
  "isEnabled": true
}
```

**Web Search (sse):**

```json
{
  "name": "web-search",
  "type": "sse",
  "url": "https://api.example.com/mcp/search",
  "headers": { "Authorization": "Bearer your-token" },
  "isEnabled": true
}
```

</details>

<details>
<summary> Agent Mode </summary>

### **Agent Mode**

When MCP servers are enabled, the extension operates in **Agent Mode**:

- **Max Steps**: Configure up to 15 tool execution steps
- **Tool Chaining**: Automatic multi-step workflows
- **Error Handling**: Robust error recovery and retry logic
- **Progress Tracking**: Real-time tool execution feedback

</details>

## Configurations

<details>

<summary> Full list of configuration options </summary>

### **Core Configuration**

| Setting                     | Default                     | Description                                                                                                                                         |
| --------------------------- | --------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------- |
| `chatgpt.gpt3.provider`     | `Auto`                      | AI Provider: Auto, OpenAI, Azure, AzureAI, Anthropic, GitHubCopilot, Google, Mistral, xAI, Together, DeepSeek, Groq, Perplexity, OpenRouter, Ollama |
| `chatgpt.gpt3.apiKey`       |                             | API key for your chosen provider                                                                                                                    |
| `chatgpt.gpt3.apiBaseUrl`   | `https://api.openai.com/v1` | API base URL for your provider                                                                                                                      |
| `chatgpt.gpt3.model`        | `gpt-4o`                    | Model to use for conversations                                                                                                                      |
| `chatgpt.gpt3.customModel`  |                             | Custom model name when using `custom` model option                                                                                                  |
| `chatgpt.gpt3.organization` |                             | Organization ID (OpenAI only)                                                                                                                       |

### **Model Parameters**

| Setting                    | Default         | Description                                        |
| -------------------------- | --------------- | -------------------------------------------------- |
| `chatgpt.gpt3.maxTokens`   | `0` (unlimited) | Maximum tokens to generate in completion           |
| `chatgpt.gpt3.temperature` | `1`             | Sampling temperature (0-2). Higher = more creative |
| `chatgpt.gpt3.top_p`       | `1`             | Nucleus sampling parameter (0-1)                   |
| `chatgpt.systemPrompt`     |                 | System prompt for the AI assistant                 |

### **DeepClaude (Reasoning + Chat) Configuration**

| Setting                               | Default                     | Description                                                                                             |
| ------------------------------------- | --------------------------- | ------------------------------------------------------------------------------------------------------- |
| `chatgpt.gpt3.reasoning.provider`     | `Auto`                      | Provider for reasoning model (Auto, OpenAI, Azure, AzureAI, Google, DeepSeek, Groq, OpenRouter, Ollama) |
| `chatgpt.gpt3.reasoning.apiKey`       |                             | API key for reasoning model                                                                             |
| `chatgpt.gpt3.reasoning.apiBaseUrl`   | `https://api.openai.com/v1` | API base URL for reasoning model                                                                        |
| `chatgpt.gpt3.reasoning.model`        |                             | Model to use for reasoning (e.g., deepseek-reasoner, o1)                                                |
| `chatgpt.gpt3.reasoning.organization` |                             | Organization ID for reasoning model (OpenAI only)                                                       |

### **Agent & MCP Configuration**

| Setting                 | Default | Description                                         |
| ----------------------- | ------- | --------------------------------------------------- |
| `chatgpt.gpt3.maxSteps` | `15`    | Maximum steps for agent mode when using MCP servers |

### **Feature Toggles**

| Setting                                | Default | Description                                                               |
| -------------------------------------- | ------- | ------------------------------------------------------------------------- |
| `chatgpt.gpt3.generateCode-enabled`    | `true`  | Enable code generation context menu                                       |
| `chatgpt.gpt3.searchGrounding.enabled` | `false` | Enable search grounding (Gemini models only)                              |
| `chatgpt.gpt3.responsesAPI.enabled`    | `false` | Enable OpenAI Responses API. Only available for OpenAI/AzureOpenAI models |

### **Prompt Prefixes & Context Menu**

| Setting                                      | Default                                  | Description                                 |
| -------------------------------------------- | ---------------------------------------- | ------------------------------------------- |
| `chatgpt.promptPrefix.addTests`              | `Implement tests for the following code` | Prompt for generating unit tests            |
| `chatgpt.promptPrefix.addTests-enabled`      | `true`                                   | Enable "Add Tests" context menu item        |
| `chatgpt.promptPrefix.findProblems`          | `Find problems with the following code`  | Prompt for finding bugs and issues          |
| `chatgpt.promptPrefix.findProblems-enabled`  | `true`                                   | Enable "Find Problems" context menu item    |
| `chatgpt.promptPrefix.optimize`              | `Optimize the following code`            | Prompt for code optimization                |
| `chatgpt.promptPrefix.optimize-enabled`      | `true`                                   | Enable "Optimize" context menu item         |
| `chatgpt.promptPrefix.explain`               | `Explain the following code`             | Prompt for code explanation                 |
| `chatgpt.promptPrefix.explain-enabled`       | `true`                                   | Enable "Explain" context menu item          |
| `chatgpt.promptPrefix.addComments`           | `Add comments for the following code`    | Prompt for adding documentation             |
| `chatgpt.promptPrefix.addComments-enabled`   | `true`                                   | Enable "Add Comments" context menu item     |
| `chatgpt.promptPrefix.completeCode`          | `Complete the following code`            | Prompt for code completion                  |
| `chatgpt.promptPrefix.completeCode-enabled`  | `true`                                   | Enable "Complete Code" context menu item    |
| `chatgpt.promptPrefix.adhoc-enabled`         | `true`                                   | Enable "Ad-hoc Prompt" context menu item    |
| `chatgpt.promptPrefix.customPrompt1`         |                                          | Your first custom prompt template           |
| `chatgpt.promptPrefix.customPrompt1-enabled` | `false`                                  | Enable first custom prompt in context menu  |
| `chatgpt.promptPrefix.customPrompt2`         |                                          | Your second custom prompt template          |
| `chatgpt.promptPrefix.customPrompt2-enabled` | `false`                                  | Enable second custom prompt in context menu |

### **User Interface**

| Setting                             | Default | Description                                     |
| ----------------------------------- | ------- | ----------------------------------------------- |
| `chatgpt.response.showNotification` | `false` | Show notification when AI responds              |
| `chatgpt.response.autoScroll`       | `true`  | Auto-scroll to bottom when new content is added |

</details>

## How to install locally

<details>

<summary> Build and install locally </summary>

We highly recommend installing the extension directly from the VS Code Marketplace for the easiest setup and automatic updates. However, for advanced users, building and installing locally is also an option.

- Install `vsce` if you don't have it on your machine (The Visual Studio Code Extension Manager)
  - `npm install --global vsce`
- Run `vsce package`
- Follow the <a href="https://code.visualstudio.com/docs/editor/extension-marketplace#_install-from-a-vsix">instructions</a> and install manually.

```sh
npm run build
npm run package
code --uninstall-extension feiskyer.chatgpt-copilot
code --install-extension chatgpt-copilot-*.vsix
```

</details>

## Acknowledgement

<details>

<summary>Acknowledgements</summary>

Inspired by [gencay/vscode-chatgpt](https://github.com/gencay/vscode-chatgpt) project and made effortlessly accessible thanks to the intuitive client provided by the [Vercel AI Toolkit](https://sdk.vercel.ai), this extension continues the open-source legacy, bringing seamless and robust AI functionalities directly into the editor with telemetry free.

</details>

## License

This project is released under ISC License - See [LICENSE](LICENSE) for details. Copyright notice and the respective permission notices must appear in all copies.
